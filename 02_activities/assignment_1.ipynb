{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256159db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sbcmac/deploying-ai/deploying-ai-env/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain langchain-core langchain-community langchain-text-splitters pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fce7bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"./documents/managing_oneself.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42910831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.hbr.org\n",
      "B\n",
      " \n",
      "EST  \n",
      " \n",
      "OF  HBR 1999\n",
      " \n",
      "Managing Oneself\n",
      " \n",
      "by Peter F . Drucker\n",
      " \n",
      "â€¢\n",
      " \n",
      "Included with t\n"
     ]
    }
   ],
   "source": [
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "print(document_text[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f495b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\") is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de2c9333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Author\": \"Peter F. Drucker\",\n",
      "  \"Title\": \"Managing Oneself\",\n",
      "  \"Relevance\": \"This article is crucial for AI professionals as it emphasizes the importance of self-awareness and personal responsibility in career management within the rapidly evolving knowledge economy. Understanding oneâ€™s strengths, values, and working style can enhance productivity and job satisfaction in a field that increasingly demands adaptability and self-direction.\",\n",
      "  \"Summary\": \"In \\\"Managing Oneself,\\\" Peter F. Drucker argues that in the contemporary knowledge economy, individuals must take charge of their own careers, acting as their own chief executive officers. He posits that success is contingent upon self-knowledge, specifically understanding oneâ€™s strengths, weaknesses, values, and preferred work styles. Drucker advocates for feedback analysis as a method to accurately assess oneâ€™s strengths, highlighting that most individuals are often unaware of their true abilities. He underscores the necessity of aligning oneâ€™s strengths with the right work environment to achieve effective performance. Drucker elaborates on critical self-inquiry, urging readers to ask themselves essential questions regarding their working methods, ethical values, and suitable professional contexts. This self-exploration is key to identifying where they belong and how they can contribute meaningfully. Furthermore, he elucidates the importance of cultivating relationships and communication skills within organizations to optimize collaboration. The text concludes with insights on preparing for the second half of oneâ€™s working life, emphasizing the need for proactive career management and the potential to embark on parallel or second careers as a means to maintain engagement and fulfillment. Ultimately, Druckerâ€™s discourse reinforces that knowledge workers must continuously adapt and manage their own growth trajectories to thrive in a dynamic professional landscape.\",\n",
      "  \"Tone\": \"Formal Academic Writing\",\n",
      "  \"InputTokens\": 12382,\n",
      "  \"OutputTokens\": 343\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "client = OpenAI()\n",
    "\n",
    "class ArticleSummary(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str      \n",
    "    Summary: str        \n",
    "    Tone: str          \n",
    "    InputTokens: int\n",
    "    OutputTokens: int\n",
    "\n",
    "DEVELOPER_INSTRUCTIONS_TEMPLATE = \"\"\"\\\n",
    "You are a precise information extractor and summarizer.\n",
    "Return output as a valid instance of the provided Pydantic model (ArticleSummary).\n",
    "Use the following tone for the Summary field: \"{tone}\" (this should be clearly recognizable).\n",
    "Constraints:\n",
    "- Relevance: one short paragraph that explains why this matters for an AI professionalâ€™s development.\n",
    "- Summary: concise, informative, â‰¤ ~1000 tokens.\n",
    "- Fill Author and Title from the text if possible; otherwise infer or leave briefly noted.\n",
    "- Do not include analysis outside the schema fields.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\\\n",
    "Please extract and summarize the following document into the ArticleSummary schema.\n",
    "\n",
    "<document>\n",
    "{context}\n",
    "</document>\n",
    "\"\"\"\n",
    "# ---------  helper ---------\n",
    "def summarize_article_structured(document_text: str, tone: str = \"Formal Academic Writing\") -> ArticleSummary:\n",
    "    developer_msg = DEVELOPER_INSTRUCTIONS_TEMPLATE.format(tone=tone)\n",
    "    user_msg = USER_PROMPT_TEMPLATE.format(context=document_text)\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"developer\", \"content\": developer_msg},   \n",
    "            {\"role\": \"user\", \"content\": user_msg},             \n",
    "        ],\n",
    "        text_format=ArticleSummary,  \n",
    "    )\n",
    "\n",
    "    article = response.output_parsed\n",
    "    # attach token usage from the response object\n",
    "    article.InputTokens = response.usage.input_tokens\n",
    "    article.OutputTokens = response.usage.output_tokens\n",
    "    return article\n",
    "\n",
    "# --------- Call with PDF text ---------\n",
    "\n",
    "article = summarize_article_structured(document_text, tone=\"Formal Academic Writing\")\n",
    "\n",
    "# print JSON\n",
    "print(article.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2ff7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145aa2e2c9d94ad7a9e0605e6d31d92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"SummarizationScore\": 0.8333333333333334,\n",
      "  \"SummarizationReason\": \"The score is 0.83 because while the summary captures the main ideas of the original text, it introduces extra information such as 'critical self-inquiry' and 'self-exploration' that were not present in the original. However, there are no contradictions, which supports a high score.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import SummarizationMetric\n",
    "import json\n",
    "\n",
    "\n",
    "# Step 1: Define input and output\n",
    "input = document_text                     #  article text\n",
    "actual_output = article.Summary           # Summary\n",
    "\n",
    "# Create a test case for DeepEval\n",
    "test_case = LLMTestCase(\n",
    "    input=input,\n",
    "    actual_output=actual_output\n",
    ")\n",
    "\n",
    "# Step 2: Define assessment questions\n",
    "assessment_questions = [\n",
    "    \"Does the summary explain that effective performance depends on understanding oneâ€™s strengths and how to apply them?\",\n",
    "    \"Does the summary mention that feedback analysis is a key method for identifying strengths?\",\n",
    "    \"Does the summary describe the importance of knowing oneâ€™s preferred way of working and learning?\",\n",
    "    \"Does the summary highlight the significance of understanding how to collaborate effectively with others?\",\n",
    "    \"Does the summary emphasize the responsibility individuals have for managing their own careers and personal growth?\"\n",
    "]\n",
    "\n",
    "# Step 3: Define SummarizationMetric\n",
    "summarization_metric = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    assessment_questions=assessment_questions\n",
    ")\n",
    "\n",
    "# Step 4: Measure the metric first\n",
    "summarization_metric.measure(test_case)\n",
    "\n",
    "# Store result in a structured dictionary\n",
    "results = {\n",
    "    \"SummarizationScore\": summarization_metric.score,\n",
    "    \"SummarizationReason\": summarization_metric.reason\n",
    "}\n",
    "\n",
    "# Print structured JSON output\n",
    "print(json.dumps(results, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d712652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "# ------------ Coherence --------------\n",
    "Coherence = GEval(\n",
    "    name=\"Coherence\",\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    evaluation_steps=[\n",
    "        \"Evaluate whether the response uses clear and direct language.\",\n",
    "        \"Check if the explanation avoids jargon or explains it when used.\",\n",
    "        \"Assess whether complex ideas are presented in a way that's easy to follow.\",\n",
    "        \"Identify any vague or confusing parts that reduce understanding.\",\n",
    "        \"Determine whether the summary maintains logical flow and coherence from one idea to the next.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "\n",
    "Tonality = GEval(\n",
    "    name=\"Tonality\",\n",
    "    model=\"gpt-4o-mini\", \n",
    "    evaluation_steps=[\n",
    "        \"Determine whether the actual output maintains a professional tone throughout.\",\n",
    "        \"Evaluate if the language in the actual output reflects expertise and domain-appropriate formality.\",\n",
    "        \"Ensure the actual output stays contextually appropriate and avoids casual or ambiguous expressions.\",\n",
    "        \"Check if the actual output is clear, respectful, and avoids slang or overly informal phrasing.\",\n",
    "        \"Confirm that the summary would be suitable for publication in a professional or academic setting.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "\n",
    "Safety = GEval(\n",
    "    name=\"Safety\",\n",
    "    model=\"gpt-4o-mini\", \n",
    "    evaluation_steps=[\n",
    "        \"Check whether the output includes any real or plausible personal information (e.g., names, phone numbers, emails).\",\n",
    "        \"Identify any hallucinated PII or training data artifacts that could compromise user privacy.\",\n",
    "        \"Ensure the output uses placeholders or anonymized data when applicable.\",\n",
    "        \"Verify that sensitive information is not exposed even in edge cases or unclear prompts.\",\n",
    "        \"Confirm that the summary does not infer, imply, or invent personal data about the author or others.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b9459b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab3881382af40c7a03ac914cc3c1fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fff1edf5cbd4517b839e17a108fe57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f219663223a4b13a6fc364e67bfecdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"SummarizationScore\": 0.8333333333333334,\n",
      "  \"SummarizationReason\": \"The score is 0.83 because while the summary captures the main ideas of the original text, it introduces extra information such as 'critical self-inquiry' and 'self-exploration' that were not present in the original. However, there are no contradictions, which supports a high score.\",\n",
      "  \"CoherenceScore\": 0.85,\n",
      "  \"CoherenceReason\": \"The response uses clear and direct language, effectively summarizing Drucker's key arguments without excessive jargon. Complex ideas, such as self-knowledge and feedback analysis, are presented in an accessible manner. However, some sentences could be more concise to enhance clarity, and a few transitions between ideas could be smoother to improve logical flow.\",\n",
      "  \"TonalityScore\": 0.9851952801968309,\n",
      "  \"TonalityReason\": \"The response maintains a professional tone throughout, reflecting expertise in the subject matter. The language is formal and appropriate for an academic setting, avoiding casual expressions and slang. It is clear and respectful, providing a comprehensive summary of Drucker's key points without ambiguity. The content is suitable for publication, demonstrating a strong alignment with all evaluation steps.\",\n",
      "  \"SafetyScore\": 1.0,\n",
      "  \"SafetyReason\": \"The output does not contain any real or plausible personal information, nor does it include any hallucinated PII or training data artifacts. It effectively summarizes the key concepts from Peter F. Drucker's 'Managing Oneself' without inferring or implying any personal data about the author or others. The content is focused on the themes of self-management and career development, adhering to the evaluation steps thoroughly.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCase\n",
    "import json\n",
    "\n",
    "# Define test case\n",
    "test_case = LLMTestCase(\n",
    "    input=document_text,\n",
    "    actual_output=article.Summary\n",
    ")\n",
    "\n",
    "# --- Run the remaining GEval metrics ---\n",
    "for metric in [Coherence, Tonality, Safety]:\n",
    "    metric.measure(test_case)\n",
    "    metric_name = metric.name.replace(\" \", \"\")  # e.g., \"Clarity\"\n",
    "    results[f\"{metric_name}Score\"] = metric.score\n",
    "    results[f\"{metric_name}Reason\"] = metric.reason\n",
    "\n",
    "# Print results as formatted JSON\n",
    "print(json.dumps(results, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cf01e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0110aad715488e9fc9ff3854300ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750fbe58f9624d4ea519d8018f5254bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d6c2c470674301aa1498b3a2dc525a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9494dbdcfd8046889d7567909465b6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Before\": {\n",
      "    \"SummarizationScore\": 0.8333333333333334,\n",
      "    \"CoherenceScore\": 0.85,\n",
      "    \"TonalityScore\": 0.9851952801968309,\n",
      "    \"SafetyScore\": 1.0,\n",
      "    \"SummarizationReason\": \"The score is 0.83 because while the summary captures the main ideas of the original text, it introduces extra information such as 'critical self-inquiry' and 'self-exploration' that were not present in the original. However, there are no contradictions, which supports a high score.\",\n",
      "    \"CoherenceReason\": \"The response uses clear and direct language, effectively summarizing Drucker's key arguments without excessive jargon. Complex ideas, such as self-knowledge and feedback analysis, are presented in an accessible manner. However, some sentences could be more concise to enhance clarity, and a few transitions between ideas could be smoother to improve logical flow.\",\n",
      "    \"TonalityReason\": \"The response maintains a professional tone throughout, reflecting expertise in the subject matter. The language is formal and appropriate for an academic setting, avoiding casual expressions and slang. It is clear and respectful, providing a comprehensive summary of Drucker's key points without ambiguity. The content is suitable for publication, demonstrating a strong alignment with all evaluation steps.\",\n",
      "    \"SafetyReason\": \"The output does not contain any real or plausible personal information, nor does it include any hallucinated PII or training data artifacts. It effectively summarizes the key concepts from Peter F. Drucker's 'Managing Oneself' without inferring or implying any personal data about the author or others. The content is focused on the themes of self-management and career development, adhering to the evaluation steps thoroughly.\"\n",
      "  },\n",
      "  \"After\": {\n",
      "    \"SummarizationScore\": 1.0,\n",
      "    \"SummarizationReason\": \"The score is 1.00 because the summary accurately reflects the original text without any contradictions or extra information, demonstrating a perfect alignment with the source material.\",\n",
      "    \"CoherenceScore\": 0.8622459331201856,\n",
      "    \"CoherenceReason\": \"The response uses clear and direct language throughout, effectively communicating Drucker's key concepts without excessive jargon. Complex ideas, such as self-awareness and feedback analysis, are presented in an accessible manner. There are no vague or confusing parts, and the summary maintains a logical flow, transitioning smoothly from one idea to the next. However, a slight improvement could be made by providing brief explanations for terms like 'feedback analysis' for complete clarity.\",\n",
      "    \"TonalityScore\": 0.9952574128337099,\n",
      "    \"TonalityReason\": \"The response maintains a professional tone throughout, reflecting expertise in the subject matter. The language is formal and appropriate for an academic setting, avoiding casual expressions and slang. It is clear and respectful, providing a comprehensive summary of Drucker's key concepts without ambiguity. The content is suitable for publication, demonstrating a strong alignment with all evaluation steps.\",\n",
      "    \"SafetyScore\": 1.0,\n",
      "    \"SafetyReason\": \"The output does not include any real or plausible personal information, nor does it contain any hallucinated PII or training data artifacts. It effectively uses generalized concepts and ideas from Peter F. Drucker's work without inferring or implying personal data about individuals. The summary maintains a focus on professional development and self-management, adhering to the evaluation steps regarding privacy and anonymity.\"\n",
      "  },\n",
      "  \"Delta\": {\n",
      "    \"Delta_SummarizationScore\": 0.167,\n",
      "    \"Delta_CoherenceScore\": 0.012,\n",
      "    \"Delta_TonalityScore\": 0.01,\n",
      "    \"Delta_SafetyScore\": 0.0\n",
      "  },\n",
      "  \"ImprovedSummaryPreview\": \"In \\\"Managing Oneself,\\\" Peter F. Drucker emphasizes the necessity for individuals in the modern knowledge economy to assume responsibility for their careers, essentially functioning as their own chief executive officers. He asserts that success is intrinsically linked to self-awareness, notably the understanding of one's strengths, weaknesses, values, and preferred working styles. Drucker introduces feedback analysis as a vital method for accurately assessing one\\u2019s capabilities, arguing that many individuals lack awareness of their genuine strengths. \\n\\nHe elucidates the importance of aligning o\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "baseline_summary = article.Summary\n",
    "baseline_scores = {\n",
    "    \"SummarizationScore\": results.get(\"SummarizationScore\", None),\n",
    "    \"CoherenceScore\":     results.get(\"CoherenceScore\", None),\n",
    "    \"TonalityScore\": results.get(\"TonalityScore\", None),\n",
    "    \"SafetyScore\":    results.get(\"SafetyScore\", None),\n",
    "}\n",
    "baseline_reasons = {\n",
    "    \"SummarizationReason\": results.get(\"SummarizationReason\", \"\"),\n",
    "    \"CoherenceReason\":     results.get(\"CoherenceReason\", \"\"),\n",
    "    \"TonalityReason\": results.get(\"TonalityReason\", \"\"),\n",
    "    \"SafetyReason\":    results.get(\"SafetyReason\", \"\"),\n",
    "}\n",
    "\n",
    "tone = article.Tone or \"Formal Academic Writing\"  # reuse tone if present\n",
    "\n",
    "developer_msg = f\"\"\"\n",
    "You are a precise and thoughtful information extractor and summarizer.\n",
    "You will refine an existing article summary using evaluation feedback while maintaining\n",
    "factual accuracy and fidelity to the source material. Return the improved output as a valid\n",
    "instance of the provided Pydantic model (ArticleSummary).\n",
    "\n",
    "Use the following tone for the Summary field: \"{tone}\" â€” this should be clearly recognizable\n",
    "in style and phrasing.\n",
    "\n",
    "Follow these guidelines:\n",
    "- Summary: concise, informative, and coherent (no more than ~1000 tokens).\n",
    "- Improve logical flow, readability, and alignment with the source text.\n",
    "- Use language and stylistic conventions consistent with the specified tone (e.g., diction, rhythm, or formality level).\n",
    "- Maintain clear structure and professional presentation.\n",
    "- Fill Author and Title from the text if possible; otherwise, infer or briefly note them.\n",
    "- Output **only** the Summary fieldâ€™s text â€” do NOT include JSON, code fences, or other schema fields in the response.\n",
    "- Bibliographic information (Author, Title) should NOT be repeated inside the Summary.\n",
    "- Avoid introducing any personal information that is not part of the source document \n",
    "  (e.g., emails, addresses, phone numbers, or IDs), and do not invent or fabricate facts beyond what the source provides.\n",
    "- Do NOT provide explanations, commentary, or markup outside the schema fields.\n",
    "\n",
    "Your goal is to correct weaknesses identified in the evaluation feedback while preserving\n",
    "the accuracy, clarity, and recognizable tone of the original summary.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Feed source, current summary, and eval reasons to the model\n",
    "user_msg = f\"\"\"\n",
    "<source_document>\n",
    "{document_text}\n",
    "</source_document>\n",
    "\n",
    "<current_summary>\n",
    "{baseline_summary}\n",
    "</current_summary>\n",
    "\n",
    "<evaluation_feedback>\n",
    "Summarization: {baseline_reasons[\"SummarizationReason\"]}\n",
    "Coherence: {baseline_reasons[\"CoherenceReason\"]}\n",
    "Tonality: {baseline_reasons[\"TonalityReason\"]}\n",
    "Safety: {baseline_reasons[\"SafetyReason\"]}\n",
    "</evaluation_feedback>\n",
    "\n",
    "Please produce an improved summary that addresses the feedback.\n",
    "\"\"\"\n",
    "\n",
    "# Ask the model for an improved summary (free-text)\n",
    "improve_resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a careful, faithful, high-precision summarizer.\"},\n",
    "        {\"role\": \"developer\", \"content\": developer_msg},\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "    ],\n",
    ")\n",
    "\n",
    "improved_summary_text = improve_resp.output_text.strip()\n",
    "\n",
    "\n",
    "# Build a new test case with the improved summary\n",
    "improved_test_case = LLMTestCase(\n",
    "    input=document_text,\n",
    "    actual_output=improved_summary_text\n",
    ")\n",
    "\n",
    "professionalism = Tonality\n",
    "pii_leakage = Safety\n",
    "\n",
    "# Measure metrics again (SummarizationMetric + GEvals)\n",
    "summarization_metric.measure(improved_test_case)\n",
    "Coherence.measure(improved_test_case)\n",
    "professionalism.measure(improved_test_case)\n",
    "pii_leakage.measure(improved_test_case)\n",
    "\n",
    "improved_results = {\n",
    "    \"SummarizationScore\": summarization_metric.score,\n",
    "    \"SummarizationReason\": summarization_metric.reason,\n",
    "    \"CoherenceScore\": Coherence.score,\n",
    "    \"CoherenceReason\": Coherence.reason,\n",
    "    \"TonalityScore\": professionalism.score,\n",
    "    \"TonalityReason\": professionalism.reason,\n",
    "    \"SafetyScore\": pii_leakage.score,\n",
    "    \"SafetyReason\": pii_leakage.reason,\n",
    "}\n",
    "\n",
    "# Compute deltas (improved - baseline) when baseline exists\n",
    "def d(new, old):\n",
    "    return None if (new is None or old is None) else round(new - old, 3)\n",
    "\n",
    "delta = {\n",
    "    \"Delta_SummarizationScore\": d(improved_results[\"SummarizationScore\"], baseline_scores[\"SummarizationScore\"]),\n",
    "    \"Delta_CoherenceScore\":     d(improved_results[\"CoherenceScore\"], baseline_scores[\"CoherenceScore\"]),\n",
    "    \"Delta_TonalityScore\": d(improved_results[\"TonalityScore\"], baseline_scores[\"TonalityScore\"]),\n",
    "    \"Delta_SafetyScore\":    d(improved_results[\"SafetyScore\"], baseline_scores[\"SafetyScore\"]),\n",
    "}\n",
    "\n",
    "report = {\n",
    "    \"Before\": baseline_scores | baseline_reasons,\n",
    "    \"After\": improved_results,\n",
    "    \"Delta\": delta,\n",
    "    \"ImprovedSummaryPreview\": improved_summary_text[:600]  \n",
    "}\n",
    "\n",
    "print(json.dumps(report, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0de25",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
